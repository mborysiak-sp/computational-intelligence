{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is my project for computational intelligence based on kaggle dataset of monkeys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import (\n",
    "    Conv2D,\n",
    "    Activation,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense,\n",
    ")\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "training_directory = os.path.join(data_folder, \"training\", \"training\")\n",
    "test_directory = os.path.join(data_folder, \"validation\", \"validation\")\n",
    "labels_file = os.path.join(data_folder, \"monkey_labels.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_file)\n",
    "labels_df = labels_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "labels_df.columns = labels_df.columns.str.strip()\n",
    "labels = labels_df[\"Common Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Read images from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_image_to_vector(input_image, size=(32, 32)):\n",
    "    resized_image = cv2.resize(input_image, size)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def convert_image_to_vector_rgb(input_image, size=(32, 32)):\n",
    "    resized_image = cv2.resize(input_image, size)\n",
    "    img_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def convert_image_to_vector_cubic(input_image, size=(32, 32)):\n",
    "    resized_image = cv2.resize(input_image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def convert_image_to_vector_both(input_image, size=(32, 32)):\n",
    "    resized_image = cv2.resize(input_image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb_cubic = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb_cubic\n",
    "\n",
    "\n",
    "def normalize(input_image):\n",
    "    mean, std = input_image.mean(), input_image.std()\n",
    "    input_image = (input_image - mean) / std\n",
    "    return input_image\n",
    "\n",
    "\n",
    "def process_image(file):\n",
    "    image_file = cv2.imread(file)\n",
    "    image_pixels = convert_image_to_vector_both(image_file, size=(32, 32))\n",
    "    image_pixels = normalize(image_pixels)\n",
    "    image_label = file.split(os.path.sep)[-2]\n",
    "    return image_pixels, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_images = []\n",
    "training_images_knn = []\n",
    "training_labels = []\n",
    "\n",
    "for path in Path(training_directory).rglob(\"*.jpg\"):\n",
    "     image, label = process_image(str(path))\n",
    "     training_images.append(image)\n",
    "     training_images_knn.append(image.flatten())\n",
    "\n",
    "     training_labels.append(label)\n",
    "\n",
    "test_images = []\n",
    "test_images_knn = []\n",
    "test_labels = []\n",
    "\n",
    "for path in Path(test_directory).rglob(\"*.jpg\"):\n",
    "     image, label = process_image(str(path))\n",
    "     test_images.append(image)\n",
    "     test_labels.append(label)\n",
    "     test_images_knn.append(image.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"labels\"]=training_labels\n",
    "lab = df[\"labels\"]\n",
    "counts = lab.value_counts()\n",
    "sns.countplot(counts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images_knn = np.array(test_images_knn)\n",
    "\n",
    "training_images = np.array(training_images)\n",
    "training_labels = np.array(training_labels)\n",
    "training_images_knn = np.array(training_images_knn)\n",
    "\n",
    "num_classes = len(np.unique(training_labels))\n",
    "label_encoder = LabelEncoder()\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "training_labels = np_utils.to_categorical(training_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=7)\n",
    "model.fit(training_images_knn, training_labels)\n",
    "acc = model.score(test_images_knn, test_labels)\n",
    "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Only needed when flattening the image before\n",
    "# training_images = training_images.reshape(-1, 32, 32, 3)\n",
    "# test_images = test_images.reshape(-1, 32, 32, 3)\n",
    "# normalizing the data to help with the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# model.compile(\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     optimizer=\"rmsprop\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reduce_learning_rate = ReduceLROnPlateau(monitor=\"loss\",\n",
    "                                         factor=0.1,\n",
    "                                         patience=2,\n",
    "                                         cooldown=1,\n",
    "                                         min_lr=0.00001,\n",
    "                                         verbose=1)\n",
    "\n",
    "checkpoint_filepath = \"checkpoint.h5\"\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor=\"accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True)\n",
    "\n",
    "# model.fit(\n",
    "#     training_images,\n",
    "#     training_labels,\n",
    "#     epochs=50,\n",
    "#     callbacks=[reduce_learning_rate],\n",
    "#     steps_per_epoch= training_images.size\n",
    "# )\n",
    "model.fit(training_images, training_labels, epochs=30, callbacks=[model_checkpoint_callback, ])\n",
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"\\nTest accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "n = 200\n",
    "test_image = test_images[n]\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "prediction = model.predict(test_image, batch_size=1)\n",
    "print(labels[np.argmax(prediction)])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "names = [\n",
    "    \"Alouatta Palliata - Mantled Howler\",\n",
    "    \"Trythrocebus Patas - Patas Monkey\",\n",
    "    \"Cacajao Calvus - Bald Uakari\",\n",
    "    \"Macaca Fuscata - Japanese Macaque\",\n",
    "    \"Cebuella Pygmea - Pygmy Marmoset\",\n",
    "    \"Cebus Capucinus - White Headed Capuchin\",\n",
    "    \"Mico Argentatus - Silvery Marmoset\",\n",
    "    \"Saimiri Sciureus - Common Squirrel Monkey\",\n",
    "    \"Aotus Nigriceps - Black Headed Night Monkey\",\n",
    "    \"Trachypithecus Johnii - Nilgiri Langur\"\n",
    "]\n",
    "\n",
    "\n",
    "IMG_SIZE = 32\n",
    "size = (IMG_SIZE,IMG_SIZE)\n",
    "n_CLASS = 10\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_set = datagen.flow_from_directory(\n",
    "    training_directory,\n",
    "    target_size = size,\n",
    "    batch_size=32,\n",
    "    seed = 42,\n",
    "    subset=\"training\",\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_set = datagen.flow_from_directory(\n",
    "    training_directory,\n",
    "    target_size = size,\n",
    "    batch_size=32,\n",
    "    seed = 42,\n",
    "    subset=\"validation\",\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "\n",
    "test_set = datagen.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = size,\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.optimizers import  Adam\n",
    "from keras.callbacks import  ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(EfficientNetB3(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = \"imagenet\"))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = \"relu\", bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(n_CLASS, activation = \"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "monkey_model = create_model()\n",
    "monkey_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(monkey_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "STEP_SIZE_TRAIN = train_set.n//train_set.batch_size\n",
    "STEP_SIZE_VALID = val_set.n//val_set.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Model_fit():\n",
    "\n",
    "    monkey_model = create_model()\n",
    "\n",
    "    \"\"\"Compiling the model\"\"\"\n",
    "\n",
    "    monkey_model.compile(\n",
    "        optimizer = Adam(learning_rate = 1e-3),\n",
    "                        loss =\"categorical_crossentropy\",\n",
    "                        metrics = [\"acc\"])\n",
    "    es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5,\n",
    "                       restore_best_weights=True, verbose=1)\n",
    "\n",
    "    checkpoint_cb = ModelCheckpoint(\"Cassava_best_model.h5\",\n",
    "                                    save_best_only=True,\n",
    "                                    monitor = \"val_loss\",\n",
    "                                    mode=\"min\")\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\",\n",
    "                                  factor = 0.3,\n",
    "                                  patience = 3,\n",
    "                                  min_lr = 1e-5,\n",
    "                                  mode = \"min\",\n",
    "                                  verbose = 1)\n",
    "\n",
    "    history = monkey_model.fit(train_set,\n",
    "                             validation_data = val_set,\n",
    "                             epochs= EPOCHS,\n",
    "                             batch_size = 32,\n",
    "                             steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                             validation_steps = STEP_SIZE_VALID,\n",
    "                             callbacks=[es, checkpoint_cb, reduce_lr])\n",
    "\n",
    "    monkey_model.save(\"Cassava_model\"+\".h5\")\n",
    "\n",
    "    return history\n",
    "\n",
    "results = Model_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train_Cat-Acc: \", max(results.history[\"acc\"]))\n",
    "print(\"Val_Cat-Acc: \", max(results.history[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(training_directory,\n",
    "                                                    target_size=(32,32),\n",
    "                                                    batch_size= 64,\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\")\n",
    "\n",
    "# Test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = test_datagen.flow_from_directory(test_directory,\n",
    "                                                  target_size=(32,32),\n",
    "                                                  batch_size=64,\n",
    "                                                  seed=1,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "validation_num = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "monkey_model = Sequential()\n",
    "monkey_model.add(Conv2D(32,(3,3), input_shape=(32,32,3), activation=\"relu\"))\n",
    "monkey_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "monkey_model.add(Conv2D(32,(3,3), activation=\"relu\"))\n",
    "monkey_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "monkey_model.add(Conv2D(64,(3,3), padding=\"same\", activation=\"relu\"))\n",
    "monkey_model.add(Conv2D(64,(3,3), activation=\"relu\"))\n",
    "monkey_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "monkey_model.add(Dropout(0.25))\n",
    "\n",
    "monkey_model.add(Flatten())\n",
    "monkey_model.add(Dense(512))\n",
    "monkey_model.add(Activation(\"relu\"))\n",
    "monkey_model.add(Dropout(0.5))\n",
    "monkey_model.add(Dense(num_classes))\n",
    "monkey_model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monkey_model.compile(optimizer=\"adam\",\n",
    "                    loss=\"categorical_crossentropy\",\n",
    "                    metrics=[\"acc\"])\n",
    "monkey_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filepath=str(os.getcwd()+\"/model.h5f\")\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,\n",
    "    monitor=\"val_acc\",\n",
    "    verbose=1,\n",
    "    save_best_only=True, mode=\"max\"\n",
    ")\n",
    "callbacks_list = [checkpoint]\n",
    "batch_size = 64\n",
    "\n",
    "monkey_generator = monkey_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_num // batch_size,\n",
    "    epochs = 100,\n",
    "    validation_data = train_generator,\n",
    "    validation_steps = validation_num // batch_size,\n",
    "    callbacks = callbacks_list,\n",
    "    verbose = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}