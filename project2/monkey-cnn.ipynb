{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This is my project for computational intelligence based on kaggle dataset of monkeys."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import applications\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression, SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import (\n",
    "    Conv2D,\n",
    "    Activation,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense, GlobalAveragePooling2D,\n",
    ")\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set data folders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "training_directory = os.path.join(data_folder, \"training\", \"training\")\n",
    "test_directory = os.path.join(data_folder, \"validation\", \"validation\")\n",
    "labels_file = os.path.join(data_folder, \"monkey_labels.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_file)\n",
    "labels_df = labels_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "labels_df.columns = labels_df.columns.str.strip()\n",
    "labels = labels_df[\"Common Name\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read images from files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def convert_image_to_vector(input_image, size):\n",
    "    resized_image = cv2.resize(input_image, size)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def convert_image_to_vector_rgb(input_image, size):\n",
    "    resized_image = cv2.resize(input_image, size)\n",
    "    img_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def convert_image_to_vector_cubic(input_image, size):\n",
    "    resized_image = cv2.resize(input_image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def convert_image_to_vector_both(input_image, size):\n",
    "    resized_image = cv2.resize(input_image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb_cubic = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb_cubic\n",
    "\n",
    "\n",
    "def normalize(input_image):\n",
    "    mean, std = input_image.mean(), input_image.std()\n",
    "    input_image = (input_image - mean) / std\n",
    "    return input_image\n",
    "\n",
    "\n",
    "def process_image(file, size):\n",
    "    image_file = cv2.imread(file)\n",
    "    image_pixels = convert_image_to_vector_both(image_file, size=size)\n",
    "    image_pixels = normalize(image_pixels)\n",
    "    image_label = file.split(os.path.sep)[-2][1]\n",
    "    return image_pixels, image_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "size = (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "training_images = []\n",
    "training_images_flattened = []\n",
    "training_labels = []\n",
    "\n",
    "for path in Path(training_directory).rglob(\"*.jpg\"):\n",
    "    image, label = process_image(str(path), size)\n",
    "    training_images.append(image)\n",
    "    training_images_flattened.append(image.flatten())\n",
    "    training_labels.append(label)\n",
    "\n",
    "test_images = []\n",
    "test_images_flattened = []\n",
    "test_labels = []\n",
    "\n",
    "for path in Path(test_directory).rglob(\"*.jpg\"):\n",
    "    image, label = process_image(str(path), size)\n",
    "    test_images.append(image)\n",
    "    test_labels.append(label)\n",
    "    test_images_flattened.append(image.flatten())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot data structure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"labels\"] = training_labels\n",
    "lab = df[\"labels\"]\n",
    "\n",
    "counts = lab.value_counts()\n",
    "counts = pd.DataFrame(counts)\n",
    "counts.index.astype(int)\n",
    "counts = counts.sort_index()\n",
    "counts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "training_labels_df = pd.DataFrame(labels)\n",
    "training_labels_df.reset_index(drop=True, inplace=True)\n",
    "training_labels_df = training_labels_df.merge(counts, left_index=True, right_index=True, how=\"left\")\n",
    "training_labels_df.set_index(\"Common Name\", inplace=True)\n",
    "training_labels_df.plot(kind=\"bar\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"labels\"] = test_labels\n",
    "lab = df[\"labels\"]\n",
    "counts = lab.value_counts()\n",
    "counts = pd.DataFrame(counts)\n",
    "counts.index.astype(int)\n",
    "counts = counts.sort_index()\n",
    "counts.reset_index(drop=True, inplace=True)\n",
    "test_labels_df = pd.DataFrame(labels)\n",
    "test_labels_df.reset_index(drop=True, inplace=True)\n",
    "test_labels_df = test_labels_df.merge(counts, left_index=True, right_index=True, how=\"left\")\n",
    "test_labels_df.set_index(\"Common Name\", inplace=True)\n",
    "test_labels_df.plot(kind=\"bar\")\n",
    "print(len(test_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images_flattened = np.array(test_images_flattened)\n",
    "training_labels_for_flattened = training_labels\n",
    "\n",
    "training_images = np.array(training_images)\n",
    "training_labels = np.array(training_labels)\n",
    "training_images_flattened = np.array(training_images_flattened)\n",
    "test_labels_for_flattened = test_labels\n",
    "\n",
    "num_classes = len(np.unique(training_labels))\n",
    "label_encoder = LabelEncoder()\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "training_labels = np_utils.to_categorical(training_labels, num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test linear and logistic regression using SGD classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sgd_lin = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "sgd_lin.fit(training_images_flattened, training_labels_for_flattened)\n",
    "y_pred = sgd_lin.predict(test_images_flattened)\n",
    "print(\n",
    "    'SGD-linear percentage correct: ',\n",
    "    100*np.sum(y_pred == test_labels_for_flattened)/len(test_labels_for_flattened)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sgd_log = SGDClassifier(loss=\"log\", max_iter=1000, tol=1e-3)\n",
    "sgd_log.fit(training_images_flattened, training_labels_for_flattened)\n",
    "y_pred = sgd_log.predict(test_images_flattened)\n",
    "print(\n",
    "    'SGD-logistic percentage correct: ',\n",
    "    100*np.sum(y_pred == test_labels_for_flattened)/len(test_labels_for_flattened)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test KNN classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model7 = KNeighborsClassifier(n_neighbors=7)\n",
    "model14 = KNeighborsClassifier(n_neighbors=14)\n",
    "model2 = KNeighborsClassifier(n_neighbors=2)\n",
    "model1 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "model1.fit(training_images_flattened, training_labels)\n",
    "model2.fit(training_images_flattened, training_labels)\n",
    "model7.fit(training_images_flattened, training_labels)\n",
    "model14.fit(training_images_flattened, training_labels)\n",
    "\n",
    "acc1 = model1.score(test_images_flattened, test_labels)\n",
    "acc2 = model2.score(test_images_flattened, test_labels)\n",
    "acc7 = model7.score(test_images_flattened, test_labels)\n",
    "acc14 = model14.score(test_images_flattened, test_labels)\n",
    "\n",
    "print(\"Accuracy for 1n: {:.2f}%\".format(acc1 * 100))\n",
    "print(\"Accuracy for 2n: {:.2f}%\".format(acc2 * 100))\n",
    "print(\"Accuracy for 7n: {:.2f}%\".format(acc7 * 100))\n",
    "print(\"Accuracy for 14n: {:.2f}%\".format(acc14 * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "channels=3\n",
    "seed=1337\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "\n",
    "# Training generator\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory(training_directory,\n",
    "                                                    target_size=size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    seed=seed,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "# Test generator\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = test_data_generator.flow_from_directory(test_directory,\n",
    "                                                  target_size=size,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  seed=seed,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implement models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_resnet_model = applications.resnet50.ResNet50(\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "x = base_resnet_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "resnet_model = Model(inputs = base_resnet_model.input, outputs = predictions)\n",
    "resnet_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "resnet_model.summary()\n",
    "keras.utils.plot_model(resnet_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit models\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    mode=\"auto\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = \"loss\",\n",
    "    factor = 0.3,\n",
    "    patience = 3,\n",
    "    min_lr = 1e-5,\n",
    "    mode = \"auto\",\n",
    "    verbose = 1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[es]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_model.save(f\"ModelResNet{IMG_SIZE}im_genwithout_rl.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    training_images,\n",
    "    training_labels,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[es]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(f\"ModelSimple{IMG_SIZE}with_rl.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Residual Network model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(resnet_model.evaluate(validation_generator, verbose=2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simple model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Testing simple\")\n",
    "test_loss, test_acc = model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2\n",
    ")\n",
    "print(\"\\nTest accuracy:\", test_acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test on one image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = 200\n",
    "test_image = test_images[n]\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "prediction = model.predict(test_image, batch_size=1)\n",
    "print(labels[np.argmax(prediction)])\n",
    "print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test saved models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def handle_model(path):\n",
    "    print(path.name)\n",
    "    model = tf.keras.models.load_model(path)\n",
    "    y_true = test_labels_for_flattened.astype(np.int)\n",
    "    if \"im_gen\" in str(path.name):\n",
    "        y_pred = model.predict(validation_generator, verbose=2)\n",
    "        predictions = np.argmax(y_pred, axis=1)\n",
    "        print(model.evaluate(validation_generator, verbose=2))\n",
    "        sns.heatmap(metrics.confusion_matrix(predictions, y_true), annot=True, fmt=\"d\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        y_pred = model.predict(test_images)\n",
    "        predictions = np.argmax(y_pred, axis=1)\n",
    "        print(model.evaluate(test_images, test_labels, verbose=2))\n",
    "        sns.heatmap(metrics.confusion_matrix(predictions, y_true), annot=True, fmt=\"d\")\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for path in Path(\"./\").rglob(\"*.h5\"):\n",
    "    if \"32\" in str(path.name):\n",
    "        handle_model(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}