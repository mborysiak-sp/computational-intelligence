{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "# %load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This is my project for computational intelligence based on kaggle dataset of monkeys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.python.keras.layers import (\n",
    "    Conv2D,\n",
    "    Activation,\n",
    "    MaxPooling2D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense,\n",
    ")\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Set data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_folder = \"data\"\n",
    "training_directory = os.path.join(data_folder, \"training\", \"training\")\n",
    "test_directory = os.path.join(data_folder, \"validation\", \"validation\")\n",
    "labels_file = os.path.join(data_folder, \"monkey_labels.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(labels_file)\n",
    "labels_df = labels_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "labels_df.columns = labels_df.columns.str.strip()\n",
    "labels = labels_df[\"Common Name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Read images from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convert_image_to_vector(input_image, size=(150, 150)):\n",
    "    resized_image = cv2.resize(input_image, size)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def convert_image_to_vector_rgb(input_image, size=(150, 150)):\n",
    "    resized_image = cv2.resize(input_image, size)\n",
    "    img_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "def convert_image_to_vector_cubic(input_image, size=(150, 150)):\n",
    "    resized_image = cv2.resize(input_image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "def convert_image_to_vector_both(input_image, size=(150, 150)):\n",
    "    resized_image = cv2.resize(input_image, size, interpolation=cv2.INTER_CUBIC)\n",
    "    img_rgb_cubic = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb_cubic\n",
    "\n",
    "\n",
    "def normalize(input_image):\n",
    "    mean, std = input_image.mean(), input_image.std()\n",
    "    input_image = (input_image - mean) / std\n",
    "    return input_image\n",
    "\n",
    "\n",
    "def process_image(file):\n",
    "    image_file = cv2.imread(file)\n",
    "    image_pixels = convert_image_to_vector_both(image_file, size=(150, 150))\n",
    "    image_pixels = normalize(image_pixels)\n",
    "    image_label = file.split(os.path.sep)[-2][1]\n",
    "    return image_pixels, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_images = []\n",
    "training_images_flattened = []\n",
    "training_labels = []\n",
    "\n",
    "for path in Path(training_directory).rglob(\"*.jpg\"):\n",
    "    image, label = process_image(str(path))\n",
    "    training_images.append(image)\n",
    "    training_images_flattened.append(image.flatten())\n",
    "    training_labels.append(label)\n",
    "\n",
    "test_images = []\n",
    "test_images_flattened = []\n",
    "test_labels = []\n",
    "\n",
    "for path in Path(test_directory).rglob(\"*.jpg\"):\n",
    "    image, label = process_image(str(path))\n",
    "    test_images.append(image)\n",
    "    test_labels.append(label)\n",
    "    test_images_flattened.append(image.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               mantled_howler\n",
      "1                 patas_monkey\n",
      "2                  bald_uakari\n",
      "3             japanese_macaque\n",
      "4               pygmy_marmoset\n",
      "5        white_headed_capuchin\n",
      "6             silvery_marmoset\n",
      "7       common_squirrel_monkey\n",
      "8    black_headed_night_monkey\n",
      "9               nilgiri_langur\n",
      "Name: Common Name, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"labels\"] = training_labels\n",
    "lab = df[\"labels\"]\n",
    "counts = lab.value_counts()\n",
    "sns.countplot(data=counts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "test_images_flattened = np.array(test_images_flattened)\n",
    "training_labels_for_flattened = training_labels\n",
    "\n",
    "training_images = np.array(training_images)\n",
    "training_labels = np.array(training_labels)\n",
    "training_images_flattened = np.array(training_images_flattened)\n",
    "test_labels_for_flattened = test_labels\n",
    "\n",
    "num_classes = len(np.unique(training_labels))\n",
    "label_encoder = LabelEncoder()\n",
    "training_labels = label_encoder.fit_transform(training_labels)\n",
    "test_labels = label_encoder.fit_transform(test_labels)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)\n",
    "training_labels = np_utils.to_categorical(training_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15326032  0.08908637 -0.57832269 ...  0.46129527  0.14042553\n",
      "  -0.50131395]\n",
      " [-0.57261757 -0.28969608 -1.17174544 ...  0.9252021   0.69220793\n",
      "   0.50914108]\n",
      " [-1.24023896 -0.43579569 -0.59668434 ... -0.65518931 -0.5820581\n",
      "  -0.97696662]\n",
      " ...\n",
      " [ 1.41790021  1.43556472  1.22359059 ...  0.18138443  0.57000368\n",
      "  -0.93147977]\n",
      " [ 1.08150812  0.68379774 -0.01804409 ... -0.2753861   0.26269264\n",
      "  -0.97722794]\n",
      " [ 1.6093684   1.6382488   1.5660478  ...  1.19060261  1.06064081\n",
      "   1.01732021]]\n",
      "[[ 0.15326032  0.08908637 -0.57832269 ...  0.46129527  0.14042553\n",
      "  -0.50131395]\n",
      " [-0.57261757 -0.28969608 -1.17174544 ...  0.9252021   0.69220793\n",
      "   0.50914108]\n",
      " [-1.24023896 -0.43579569 -0.59668434 ... -0.65518931 -0.5820581\n",
      "  -0.97696662]\n",
      " ...\n",
      " [ 1.41790021  1.43556472  1.22359059 ...  0.18138443  0.57000368\n",
      "  -0.93147977]\n",
      " [ 1.08150812  0.68379774 -0.01804409 ... -0.2753861   0.26269264\n",
      "  -0.97722794]\n",
      " [ 1.6093684   1.6382488   1.5660478  ...  1.19060261  1.06064081\n",
      "   1.01732021]]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLinAlgError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-50-6b72910f417e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;31m# test_data = pd.DataFrame(test_images_flattened).replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[0mlin_reg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mLinearRegression\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[0mlin_reg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtraining_images_flattened\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtraining_labels_for_flattened\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlin_reg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_images_flattened\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programowanko\\computational-intelligence\\project2\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    567\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    568\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_residues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrank_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msingular_\u001B[0m \u001B[1;33m=\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 569\u001B[1;33m                 \u001B[0mlinalg\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlstsq\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    570\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\programowanko\\computational-intelligence\\project2\\venv\\lib\\site-packages\\scipy\\linalg\\basic.py\u001B[0m in \u001B[0;36mlstsq\u001B[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001B[0m\n\u001B[0;32m   1205\u001B[0m                                                cond, False, False)\n\u001B[0;32m   1206\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1207\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mLinAlgError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"SVD did not converge in Linear Least Squares\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1208\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1209\u001B[0m             raise ValueError('illegal value in %d-th argument of internal %s'\n",
      "\u001B[1;31mLinAlgError\u001B[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "# LINEAR REGRESSION\n",
    "print(training_images_flattened)\n",
    "# print(training_labels_for_flattened)\n",
    "# print(test_images_flattened)\n",
    "# print(test_labels_for_flattened)\n",
    "normalzed = normalize(training_images_flattened)\n",
    "print(normalzed)\n",
    "# data = pd.DataFrame(training_images_flattened).replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()\n",
    "# test_data = pd.DataFrame(test_images_flattened).replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(normalize(training_images_flattened), training_labels_for_flattened)\n",
    "predictions = lin_reg.predict(test_images_flattened)\n",
    "\n",
    "plt.scatter(training_images_flattened, training_labels_for_flattened, color=\"black\")\n",
    "plt.plot(test_images_flattened, test_labels_for_flattened, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TEST KNN classifier\n",
    "model7 = KNeighborsClassifier(n_neighbors=7)\n",
    "model14 = KNeighborsClassifier(n_neighbors=14)\n",
    "model2 = KNeighborsClassifier(n_neighbors=2)\n",
    "model1 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "model1.fit(training_images_flattened, training_labels)\n",
    "model2.fit(training_images_flattened, training_labels)\n",
    "model7.fit(training_images_flattened, training_labels)\n",
    "model14.fit(training_images_flattened, training_labels)\n",
    "\n",
    "acc1 = model1.score(test_images_flattened, test_labels)\n",
    "acc2 = model2.score(test_images_flattened, test_labels)\n",
    "acc7 = model7.score(test_images_flattened, test_labels)\n",
    "acc14 = model14.score(test_images_flattened, test_labels)\n",
    "\n",
    "print(\"Accuracy for 1n: {:.2f}%\".format(acc1 * 100))\n",
    "print(\"Accuracy for 2n: {:.2f}%\".format(acc2 * 100))\n",
    "print(\"Accuracy for 7n: {:.2f}%\".format(acc7 * 100))\n",
    "print(\"Accuracy for 14n: {:.2f}%\".format(acc14 * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    mode=\"min\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"Best_model.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor = \"loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor = \"loss\",\n",
    "    factor = 0.3,\n",
    "    patience = 3,\n",
    "    min_lr = 1e-5,\n",
    "    mode = \"min\",\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    training_images,\n",
    "    training_labels,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint_cb, es, reduce_lr]\n",
    ")\n",
    "model.save(\"Model15015032firstsimple\"+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(\n",
    "    test_images,\n",
    "    test_labels,\n",
    "    verbose=2\n",
    ")\n",
    "print(\"\\nTest accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "test_image = test_images[n]\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "prediction = model.predict(test_image, batch_size=1)\n",
    "print(labels[np.argmax(prediction)])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150\n",
    "size = (IMG_SIZE,IMG_SIZE)\n",
    "\n",
    "datagenerator = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.efficientnet.preprocess_input,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_set = datagenerator.flow_from_directory(\n",
    "    training_directory,\n",
    "    target_size = size,\n",
    "    batch_size=32,\n",
    "    seed = 42,\n",
    "    subset=\"training\",\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_set = datagenerator.flow_from_directory(\n",
    "    training_directory,\n",
    "    target_size = size,\n",
    "    batch_size=32,\n",
    "    seed = 42,\n",
    "    subset=\"validation\",\n",
    "    shuffle = True,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "\n",
    "test_set = datagenerator.flow_from_directory(\n",
    "    test_directory,\n",
    "    target_size = size,\n",
    "    batch_size = 32,\n",
    "    seed = 42,\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_generator_model = Sequential()\n",
    "image_generator_model.add(EfficientNetB3(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = \"imagenet\"))\n",
    "image_generator_model.add(GlobalAveragePooling2D())\n",
    "image_generator_model.add(Flatten())\n",
    "image_generator_model.add(Dense(512, activation = \"relu\", bias_regularizer=tf.keras.regularizers.L1L2(l1=0.01, l2=0.001)))\n",
    "image_generator_model.add(Dropout(0.7))\n",
    "image_generator_model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "image_generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(image_generator_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "STEP_SIZE_TRAIN = train_set.n//train_set.batch_size\n",
    "STEP_SIZE_VALID = val_set.n//val_set.batch_size\n",
    "\n",
    "image_generator_model.compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss =\"categorical_crossentropy\",\n",
    "    metrics = [\"acc\"]\n",
    ")\n",
    "\n",
    "\n",
    "image_generator_model.fit(\n",
    "    train_set,\n",
    "    validation_data = val_set,\n",
    "    epochs= EPOCHS,\n",
    "    batch_size = 32,\n",
    "    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "    validation_steps = STEP_SIZE_VALID,\n",
    "    callbacks=[es, reduce_lr]\n",
    ")\n",
    "print(image_generator_model.evaluate(test_set))\n",
    "image_generator_model.save(\"Model15015032second\"+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(training_directory,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size= 64,\n",
    "                                                    seed=1,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode=\"categorical\")\n",
    "\n",
    "# Test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = test_datagen.flow_from_directory(test_directory,\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=64,\n",
    "                                                  seed=1,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode=\"categorical\")\n",
    "\n",
    "train_num = train_generator.samples\n",
    "validation_num = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "monkey_model = Sequential()\n",
    "monkey_model.add(Conv2D(32,(3,3), input_shape=(150,150,3), activation=\"relu\"))\n",
    "monkey_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "monkey_model.add(Conv2D(32,(3,3), activation=\"relu\"))\n",
    "monkey_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "monkey_model.add(Conv2D(64,(3,3), padding=\"same\", activation=\"relu\"))\n",
    "monkey_model.add(Conv2D(64,(3,3), activation=\"relu\"))\n",
    "monkey_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "monkey_model.add(Dropout(0.25))\n",
    "monkey_model.add(Flatten())\n",
    "monkey_model.add(Dense(512))\n",
    "monkey_model.add(Activation(\"relu\"))\n",
    "monkey_model.add(Dropout(0.5))\n",
    "monkey_model.add(Dense(num_classes))\n",
    "monkey_model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monkey_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "monkey_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callbacks_list = [es, reduce_lr]\n",
    "batch_size = 64\n",
    "\n",
    "monkey_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = train_num // batch_size,\n",
    "    epochs = 50,\n",
    "    validation_data = train_generator,\n",
    "    validation_steps = validation_num // batch_size,\n",
    "    callbacks = callbacks_list,\n",
    "    verbose = 1\n",
    ")\n",
    "monkey_model.save(\"Model15015032third\"+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monkey_model.evaluate(validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}